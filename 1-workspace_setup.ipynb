{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "### Table of Contents\n",
    "1. [SQL Interface](#sql-interface)\n",
    "2. [Helper Methods](#helper-methods)\n",
    "2. [Pandas, extended inplace](#pandas-extended-inplace)\n",
    "2. [Format District](#format-district)\n",
    "2. [GeoDF](#geodf)\n",
    "2. [GroupedDF](#groupeddf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install numpy pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `extend-inplace` - a simple library I built, inspired by this project.\n",
    "- Docs & source here: [github.com/ryayoung/extend-inplace](https://github.com/ryayoung/extend-inplace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install extend-inplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterable, Any\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3 as sqlite\n",
    "import re\n",
    "from extend_inplace import Extend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL Interface\n",
    "\n",
    "- End-user will use `read_raw()`, `read_main()`, `write_raw()`, and `write_main()` to communicate with sqlite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_con_raw = lambda: sqlite.connect(\"data_raw.db\")\n",
    "get_con_main = lambda: sqlite.connect(\"data_main.db\")\n",
    "sql = dict(\n",
    "    raw = dict(con = get_con_raw, cache = dict()),\n",
    "    main = dict(con = get_con_main, cache = dict()),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper methods for the end-user methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _to_sql(\n",
    "    df: pd.DataFrame,\n",
    "    name: str,\n",
    "    con: str\n",
    ") -> None | int:\n",
    "    \"\"\"\n",
    "    Save/replace `df` under `name` in sqlite. Database depends on `con`\n",
    "    \"\"\"\n",
    "    res = df.to_sql(name, con=sql[con]['con'](), index=False, if_exists='replace')\n",
    "    return res\n",
    "\n",
    "\n",
    "def _format_query(\n",
    "    *args: tuple[str], # only one string arg processed\n",
    "    **kwargs: dict[str, str],\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Allow for more pythonic style of writing sql queries, for better\n",
    "    readability, user experience, and user-error prevention. Underscores\n",
    "    can be used to prefix/suffix python reserved word kwargs like FROM, IF, etc.\n",
    "    --\n",
    "    >>> _format_query(\"SELECT name, age FROM my_table\")\n",
    "    SELECT name, age FROM my_table\n",
    "    >>> _format_query(\"my_table\")\n",
    "    SELECT * FROM my_table\n",
    "    >>> _format_query(\"my_table\", WHERE = \"something = something\")\n",
    "    SELECT * FROM my_table WHERE something = something\n",
    "    >>> _format_query(\"name, age\", from_ = \"my_table\")\n",
    "    SELECT name, age FROM my_table\n",
    "    \"\"\"\n",
    "    kwarg_query = \" \".join([f'{k.strip(\"_\").upper()} {v}' for k,v in kwargs.items()])\n",
    "    if len(args) == 1:\n",
    "        if len(args[0]) == len(re.sub(r\"\\s+\", \"\", args[0])):\n",
    "            query = f\"SELECT * FROM {args[0]} \"\n",
    "        elif \"select\" not in args[0].lower():\n",
    "            query = f\"SELECT {args[0]} \"\n",
    "        else:\n",
    "            query = args[0] + \" \"\n",
    "        return query + kwarg_query\n",
    "    else:\n",
    "        return kwarg_query\n",
    "\n",
    "\n",
    "def _read_sql(\n",
    "    *args: tuple[str, ...],\n",
    "    con: str,\n",
    "    **kwargs: dict[str, str],\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    This method is specific to this script. It references global variables and funcs\n",
    "    \"\"\"\n",
    "    query = _format_query(*args, **kwargs)\n",
    "\n",
    "    if (cached := sql[con]['cache'].get(query, None)) is not None:\n",
    "        return cached.copy()\n",
    "\n",
    "    df = sql[con]['cache'][query] = pd.read_sql(query, con=sql[con]['con']())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "End-user will use these read/write methods to communicate with sqlite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_raw = lambda *args, **kwargs: _read_sql(*args, **kwargs, con='raw')\n",
    "read_main = lambda *args, **kwargs: _read_sql(*args, **kwargs, con='main')\n",
    "# def write_raw(*args, **kwargs):\n",
    "    # _to_sql(*args, **kwargs, con='raw')\n",
    "write_raw = lambda *args, **kwargs: _to_sql(*args, **kwargs, con='raw')\n",
    "write_main = lambda *args, **kwargs: _to_sql(*args, **kwargs, con='main')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def head(\n",
    "    *dfs: tuple[pd.DataFrame, ...],\n",
    "    n: int = 3,\n",
    "    with_tail: bool = False\n",
    ") -> None:\n",
    "    '''\n",
    "    Like display() and pd.DataFrame.head got married and had a kid.\n",
    "    - `with_tail` will concat head and tail together.\n",
    "    '''\n",
    "    for df in dfs:\n",
    "        print(f'{df.shape[1]} cols x {df.shape[0]} rows')\n",
    "        if with_tail:\n",
    "            display(pd.concat([df.head(n-1), df.tail(n-1)], axis=0))\n",
    "        else:\n",
    "            display(df.head(3))\n",
    "\n",
    "\n",
    "def _flatten_iterable(\n",
    "    args: Any\n",
    ") -> tuple[Any, ...]:\n",
    "    \"\"\"\n",
    "    Turns anything into a flattened tuple of non-iterable (str, bytes excluded) values\n",
    "\n",
    "    >>> _flatten_iterable(int)\n",
    "    (<class 'int'>,)\n",
    "    >>> _flatten_iterable(['hi'])\n",
    "    ('hi',)\n",
    "    >>> _flatten_iterable(['hi', (1,3, [8]), [((3,3,3))]])\n",
    "    ('hi', 1, 3, 8, 3, 3, 3)\n",
    "    \"\"\"\n",
    "\n",
    "    def valid_iterable(e: Any) -> bool:\n",
    "        if isinstance(e, Iterable) and not isinstance(e, (str, bytes)):\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def flatten(elems: Iterable[Any]):\n",
    "        for e in elems:\n",
    "            if valid_iterable(e):\n",
    "                yield from flatten(e)\n",
    "            else:\n",
    "                yield e\n",
    "\n",
    "    args = args if valid_iterable(args) else (args,)\n",
    "\n",
    "    return tuple(flatten(args))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas, extended inplace\n",
    "- Modifying pandas `DataFrame` and `Series` classes in-place with the following extra instance methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@Extend(pd.Series)\n",
    "def rename_vals_from_df(self, changes:pd.DataFrame) -> pd.Series:\n",
    "    cols = changes.columns\n",
    "    old, new = changes[cols[0]], changes[cols[1]]\n",
    "    return self.map(dict(zip(old, new)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@Extend(pd.DataFrame)\n",
    "class _:\n",
    "    def set_columns(self, *new) -> pd.DataFrame:\n",
    "        new = _flatten_iterable(new)\n",
    "        self.columns = new\n",
    "        return self\n",
    "\n",
    "\n",
    "    def rename_col(self, old:str, new:str) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Simplify syntax for renaming one column\n",
    "        \"\"\"\n",
    "        return self.rename(columns={old:new})\n",
    "\n",
    "\n",
    "    def drop_cols(self, *columns) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Simplify syntax of dropping columns\n",
    "        \"\"\"\n",
    "        cols = _flatten_iterable(columns)\n",
    "        cols = [c for c in cols if c in self.columns]\n",
    "        return self.drop(columns=cols)\n",
    "\n",
    "\n",
    "    def prefix_cols(self, cols:str or list, prefix:str) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Like df.add_prefix(), but takes a subset of columns as first positional\n",
    "        \"\"\"\n",
    "        if isinstance(cols, str):\n",
    "            cols = [cols]\n",
    "        return self.rename(columns={col: f'{prefix}{col}' for col in cols})\n",
    "\n",
    "\n",
    "    def reset_multilevel_columns(\n",
    "        self,\n",
    "        *new_columns: tuple[str | Iterable[str], ...],\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Use this after df.pivot() to flatten and rename columns.\n",
    "        \"\"\"\n",
    "        new_columns = _flatten_iterable(new_columns)\n",
    "        self = self.reset_index()\n",
    "        self.columns = self.columns.droplevel()\n",
    "        self.columns.name = None\n",
    "        self = self.set_columns(new_columns)\n",
    "        return self\n",
    "\n",
    "\n",
    "    def col_replace(\n",
    "        self,\n",
    "        text: str | dict,\n",
    "        replacement: str | None = None\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Replace a pattern in each column NAME\n",
    "        \"\"\"\n",
    "        if replacement is None:\n",
    "            if isinstance(text, dict):\n",
    "                to_replace = text\n",
    "            else:\n",
    "                raise ValueError(\"Multiple values must be passed as dict\")\n",
    "        else:\n",
    "            to_replace = {text: replacement}\n",
    "        \n",
    "        for old, new in to_replace.items():\n",
    "            for c in self.columns:\n",
    "                if c != old:\n",
    "                    self = self.rename(columns={c: c.replace(old, new)})\n",
    "        return self\n",
    "\n",
    "\n",
    "    def coerce_type(\n",
    "        self,\n",
    "        dtype: str or type,\n",
    "        subset: list = None,\n",
    "        exclude: list = None\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Iteratively try to set all columns to type\n",
    "        \"\"\"\n",
    "        df = self.copy()\n",
    "        cols = tuple(subset) if subset else tuple(self.columns)\n",
    "        if exclude:\n",
    "            cols = [c for c in cols if c not in exclude]\n",
    "        for c in cols:\n",
    "            try:\n",
    "                df[c] = df[c].astype(dtype)\n",
    "            except Exception:\n",
    "                pass\n",
    "        return df\n",
    "\n",
    "\n",
    "    def insert_at(\n",
    "        self,\n",
    "        target: str | int,\n",
    "        name: str,\n",
    "        col: pd.Series\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Insert col before target col name, or to index.\n",
    "        Like df.insert(), but takes a column name as location, instead of int \"\"\"\n",
    "        df = self.copy()\n",
    "        if isinstance(target, int):\n",
    "            idx = target\n",
    "        else:\n",
    "            idx = list(df.columns).index(target)\n",
    "        df.insert(idx, name, col)\n",
    "        return df\n",
    "\n",
    "\n",
    "    def move_col(\n",
    "        self,\n",
    "        name: str,\n",
    "        target: str | int\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Move col to before target col name, or to index.\n",
    "        - Must not mutate original dataframe (so we can chain the func\n",
    "        and re-run cells).\n",
    "        - Placement must be correct: if target column is string, always\n",
    "        place our column before the target column. If target is an index,\n",
    "        the RESULTING dataframe must have our new column in the specified index.\n",
    "        \"\"\"\n",
    "        cols = list(self.columns)\n",
    "\n",
    "        if isinstance(target, int):\n",
    "            idx = target\n",
    "            cols.remove(name)\n",
    "            cols.insert(idx, name)\n",
    "        elif isinstance(target, str):\n",
    "            idx = list(self.columns).index(target)\n",
    "            cols[cols.index(name)] = \"7dwIFmVgq5f1z\"\n",
    "            cols.insert(idx, name)\n",
    "            cols.remove(\"7dwIFmVgq5f1z\")\n",
    "\n",
    "        return self[cols]\n",
    "\n",
    "\n",
    "    def separate_by(\n",
    "        self,\n",
    "        to_match: list or str,\n",
    "        index: list = [],\n",
    "        keep: list = [],\n",
    "        start: bool = False,\n",
    "        end: bool = False,\n",
    "        mode: str = \"include\",\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Given a df and a substring, filter for columns whose name does, or\n",
    "        does not, contain a substring\n",
    "\n",
    "        to_match\n",
    "            text(s) to match\n",
    "        index\n",
    "            key columns to ignore (year, county, district, etc.)\n",
    "        keep\n",
    "            columns to ignore in matching. If \"exclude\", these columns will be removed\n",
    "        start\n",
    "            match only if column starts with `to_match` element, instead of contains\n",
    "        end\n",
    "            match only if column ends with `to_match` element, instead of contains\n",
    "        mode\n",
    "            If \"include\", returned df will include columns in `index`, `keep`, and matches\n",
    "            If \"exclude\", returned df will exclude columns in `keep`, and matches\n",
    "        \"\"\"\n",
    "        if not isinstance(to_match, list):\n",
    "            to_match = [to_match]\n",
    "\n",
    "        names = [item for sublist in [[c for c in self.columns if (\n",
    "                c.startswith(txt) if start else c.endswith(txt) if end else txt in c\n",
    "            )] for txt in to_match] for item in sublist]\n",
    "\n",
    "        if mode == 'include':\n",
    "            return self.copy()[index + keep + names]\n",
    "        if mode == 'exclude':\n",
    "            return self.copy().drop(columns = keep + names)\n",
    "\n",
    "\n",
    "    def display(self, text: bool = None, head: bool = True) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Display while chaining methods. Return self\n",
    "        \"\"\"\n",
    "        if text is not None:\n",
    "            print(text)\n",
    "        to_display = self.head(3) if head else self\n",
    "        display(to_display)\n",
    "        return self\n",
    "    \n",
    "\n",
    "    def rename_vals_from_df(self, column: str, changes: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Renames values in a column using a 2-column dataframe (old, new)\n",
    "        instead of dictionary.\n",
    "        \"\"\"\n",
    "        df = self.copy()\n",
    "        df[column] = df[column].rename_vals_from_df(changes)\n",
    "        return df\n",
    "\n",
    "\n",
    "    def rename_cols_from_df(self, changes: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Renames columns in df, mapping changes from a 2-column df (old, new)\n",
    "        \"\"\"\n",
    "        cols = changes.columns\n",
    "        old, new = changes[cols[0]], changes[cols[1]]\n",
    "        return self.rename(columns=dict(zip(old, new)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format District\n",
    "- Apply the below function to all school district columns from source, to standardize their naming conventions to allow joins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_district_name(name: str) -> str:\n",
    "    \"\"\"\n",
    "    Apply this iteratively (with pd.Series.apply())\n",
    "    to school district name columns to standardize their naming conventions\n",
    "    as best as possible prior to merging datasets with potentially\n",
    "    very different naming conventions.\n",
    "    \"\"\"\n",
    "    import re\n",
    "    name = name.upper()\n",
    "    name = re.sub('S/D', '', name)\n",
    "    name = re.sub('-|\\.|\\(|\\)|/|:', '', name)\n",
    "    name = re.sub(' CONSOLIDATED', '', name)\n",
    "    name = re.sub('\\s?SCHOOL DISTRICT', '', name)\n",
    "    \n",
    "    # Number patterns\n",
    "    name = re.sub(r' RENO\\s?(\\d+)', r'\\1', name)\n",
    "    name = re.sub(r' NO\\s?(\\d+)', r'\\1', name)\n",
    "    name = re.sub(r' RD\\s?(\\d+)', r'\\1', name)\n",
    "    name = re.sub(r' RJ\\s?(\\d+)', r'\\1', name)\n",
    "    name = re.sub(r' RE\\s?(\\d+)J?T?', r'\\1', name)\n",
    "    name = re.sub(r' R\\s?(\\d+)J?', r'\\1', name)\n",
    "    name = re.sub(r' C\\s?(\\d+)', r'\\1', name)\n",
    "\n",
    "    # Remove spaces\n",
    "    name = re.sub('\\s', '', name)\n",
    "\n",
    "    # Number patterns (text at end)\n",
    "    name = re.sub(r'(\\d+)R', r'\\1', name)\n",
    "    name = re.sub(r'(\\d+)J', r'\\1', name)\n",
    "    name = re.sub(r'(\\d+)JT', r'\\1', name)\n",
    "\n",
    "    # Delete text parts\n",
    "    name = re.sub('RURAL', '', name)\n",
    "    name = re.sub('SCHOOLS', '', name)\n",
    "    # name = re.sub('SCHOOLDISTRICT', '', name)\n",
    "    name = re.sub('SCHOOLDIST', '', name)\n",
    "    name = re.sub('WATERSHED', '', name)\n",
    "    name = name.strip()\n",
    "\n",
    "    # Replace full\n",
    "    name = name.replace(r'GILCREST', 'WELDCOUNTY')\n",
    "    name = name.replace(r'FLORENCE', 'FREMONT')\n",
    "    name = name.replace(r'CONSOLIDATED1', 'CUSTERCOUNTY1')\n",
    "    name = re.sub(r'(PUEBLOCITY)(\\d+)', r'\\1', name)\n",
    "    name = re.sub(r'^CREEDE$', r'CREEDE1', name)\n",
    "\n",
    "    name = name.strip()\n",
    "    # Push number out\n",
    "    name = re.sub(r'(.*?)(\\d+)(.*)', r'\\1\\3 \\2', name)\n",
    "    return name\n",
    "\n",
    "\n",
    "def join_conflicts(\n",
    "    df1: pd.DataFrame,\n",
    "    df2: pd.DataFrame,\n",
    "    col: str\n",
    ") -> pd.DataFrame:\n",
    "    '''\n",
    "    Use when trying to join columns and see values that aren't shared.\n",
    "    There's DEFINITELY a better way to do this. But I'm lazy, and nobody cares!\n",
    "    '''\n",
    "    import pandas as pd\n",
    "\n",
    "    col_items1 = sorted(df1[col])\n",
    "    col_items2 = sorted(df2[col])\n",
    "\n",
    "    items1_diff = [i for i in col_items1 if i not in col_items2]\n",
    "    items2_diff = [i for i in col_items2 if i not in col_items1]\n",
    "\n",
    "    # Make lists same length.\n",
    "    if len(items1_diff) > len(items2_diff):\n",
    "        items2_diff += [None] * (len(items1_diff) - len(items2_diff))\n",
    "    elif len(items2_diff) > len(items1_diff):\n",
    "        items1_diff += [None] * (len(items2_diff) - len(items1_diff))\n",
    "    \n",
    "    return pd.DataFrame(list(zip(items1_diff, items2_diff)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GeoDF\n",
    "\n",
    "- Child class of `geopy.GeoDataFrame` to provide ease of use and additional functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gp\n",
    "from shapely import wkt\n",
    "\n",
    "class GeoDF(gp.GeoDataFrame):\n",
    "\n",
    "    def __init__(self, df, geo=None, crs='epsg:4326'):\n",
    "        if type(df) == str:\n",
    "            df = pd.read_csv(df)\n",
    "        if type(df) == pd.DataFrame:\n",
    "            df = df.copy()\n",
    "\n",
    "            cols = [c for c in df.columns if c.startswith('geo_')]\n",
    "            for c in cols:\n",
    "                df[c] = df[c].fillna('GEOMETRYCOLLECTION EMPTY')\n",
    "                df[c] = gp.GeoSeries(df[c].apply(wkt.loads))\n",
    "\n",
    "            if not geo:\n",
    "                geo = cols[0]\n",
    "\n",
    "            df['geometry'] = df[geo]\n",
    "\n",
    "        super(GeoDF, self).__init__(df, crs=crs)\n",
    "    \n",
    "\n",
    "    def explore(self, tooltip=None, geo=None, **kwargs):\n",
    "        if geo:\n",
    "            self.set_geo(geo)\n",
    "        \n",
    "        if not tooltip:\n",
    "            tooltip = self.columns[0]\n",
    "            if 'county' in self.columns and 'dist' in self.columns:\n",
    "                tooltip = ['county', 'dist']\n",
    "\n",
    "        return super().loc[self['geometry'].astype(str) != 'GEOMETRYCOLLECTION EMPTY'].explore(tooltip=tooltip, **kwargs)\n",
    "\n",
    "\n",
    "    def df(self):\n",
    "        return self[self.geometry.astype(str) != 'GEOMETRYCOLLECTION EMPTY']\n",
    "\n",
    "\n",
    "    def set_geo(self, geo, crs='epsg:4326'):\n",
    "        self['geometry'] = self[geo]\n",
    "    \n",
    "\n",
    "    def copy(self):\n",
    "        return GeoDF(super().copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GroupedDF\n",
    "\n",
    "- Lets us split a dataframe into organized groups based on column names.\n",
    "- Useful for massive dataframes with too many columns to conveniently select columns manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "class GroupedDF:\n",
    "    default_index = []\n",
    "    groups: dict = None\n",
    "\n",
    "    def __init__(self, df, index=[], custom={}, show_g_names=True):\n",
    "        self.index = index\n",
    "        if self.index == []: self.index = GroupedDF.default_index\n",
    "\n",
    "        self.index = index\n",
    "        self._df = deepcopy(df)\n",
    "        self._show_g_names = show_g_names\n",
    "\n",
    "        self._custom = custom\n",
    "        self.refresh_groups()\n",
    "    \n",
    "\n",
    "    def refresh_groups(self):\n",
    "        self._dict = {g: self._df.separate_by(g, self.index, start=True, mode='include') for g in GroupedDF.groups.keys()}\n",
    "\n",
    "        if self._show_g_names == False:\n",
    "            for k, v in self._dict.items():\n",
    "                self._dict[k] = v.col_replace(f'{k}_', '')\n",
    "\n",
    "        for name, cols in self._custom.items():\n",
    "            self._dict[name] = self._df[cols]\n",
    "\n",
    "        for k, v in self._dict.items():\n",
    "            setattr(self, k, v)\n",
    "    \n",
    "\n",
    "    @classmethod\n",
    "    def set_groups(cls, items: dict or list):\n",
    "\n",
    "        if type(items) == list:\n",
    "            cls.groups = {k: \"\" for k in items}\n",
    "            return\n",
    "        \n",
    "        cls.groups = items\n",
    "\n",
    "\n",
    "    @property\n",
    "    def df(self):\n",
    "        return self._df\n",
    "    \n",
    "    @df.setter\n",
    "    def df(self, new):\n",
    "        self._df = new\n",
    "        self.refresh_groups()\n",
    "\n",
    "\n",
    "    def __getattr__(self, name):\n",
    "        return self._dict.get(name)\n",
    "\n",
    "    def __getitem__(self, name):\n",
    "        return self._dict[name]\n",
    "    \n",
    "\n",
    "    @property\n",
    "    def dict(self):\n",
    "        return self._dict\n",
    "    \n",
    "    @property\n",
    "    def show_g_names(self):\n",
    "        return self._show_g_names\n",
    "    \n",
    "    @show_g_names.setter\n",
    "    def show_g_names(self, val:bool):\n",
    "        self._show_g_names = val\n",
    "        self.refresh_groups()\n",
    "    \n",
    "\n",
    "    def display(self, rows=3, exclude=[]):\n",
    "        for k, v in self._dict.items():\n",
    "            print(k, GroupedDF.groups[k], sep=': ')\n",
    "            display(v.drop(columns=exclude).head(rows))\n",
    "            print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "908abd7e78fd4d71ba1be92795635fd82be5080a16e3cc7c1eae8bbfec458fa8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
