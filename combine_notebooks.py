# Maintainer:     Ryan Young
# Last Modified:  Dec 05, 2022

"""
Sloppy code I threw together to combine all ipynb files in a directory
with some customization. Couldn't use existing libraries because I wanted
to insert custom separators, a custom 'do not edit' header, and a way to
filter out lines, like repetitive imports or '%run setup.py' calls.
"""



import os
import json
import re

default_header = "### DO NOT EDIT: This file was generated by a script that combines all .ipynb files in the current directory."

def combine(
        filename: str = "COMBINED",
        files_to_combine: list|None = None,
        files_to_exclude: list|None = None,
        overwrite: bool = True,
        ignore: str|list = [],
        cell_filters: str|list = [],
        line_filters: str|list = [],
        header: str|list|None = default_header,
) -> None:

    ignore = ignore if isinstance(ignore, list) else [ignore]
    cell_filters = cell_filters if isinstance(cell_filters, list) else [cell_filters]
    line_filters = line_filters if isinstance(line_filters, list) else [line_filters]
    if header is not None:
        header = header if isinstance(header, list) else [header]

    ignore = [name if name.endswith(".ipynb") else name + ".ipynb" for name in ignore]

    filename = filename.strip(".ipynb")

    all_file_names = list(sorted(os.listdir())) if files_to_combine is None else files_to_combine

    all_files = (
        (name.removesuffix(".ipynb"), read_file_as_json(name)) for name in all_file_names
        if name.endswith(".ipynb")
        and name.removesuffix(".ipynb") not in ignore
        and name.removesuffix("ipynb") != filename
    )
    all_files = [
        [name, contents] for name, contents in all_files
        if contents["metadata"].get("is_combined_file", False) is False
    ]
    all_file_names = [f[0] for f in all_files]

    _, main_file_contents = all_files[0]
    main_file_contents["metadata"]["is_combined_file"] = True

    cell_groups = [contents["cells"] for _, contents in all_files]

    for i, fname in enumerate(all_file_names):
        sep = ["---\n"] * 3
        sub_header = sep + [f"# `{fname}`\n", "\n", "[BACK TO TOP ^](#top-of-page)\n", "\n"] + sep
        cell_groups[i].insert(0, new_markdown_cell(sub_header))

    cells = [item for subgroup in cell_groups for item in subgroup]

    if len(cell_filters) > 0:
        for filter_str in cell_filters:
            cells = [cell for cell in cells if filter_str not in "".join(cell["source"])]

    if len(line_filters) > 0:
        for filter_str in line_filters:
            for cell_i, cell in enumerate(cells):
                for line_i, line in enumerate(cell["source"]):
                    if filter_str in str(line):
                        cells[cell_i]["source"][line_i] = None
                        # If next is newline, remove it
                        if line_i < len(cell["source"]) - 1:
                            if cell["source"][line_i+1] == "\n":
                                cells[cell_i]["source"][line_i+1] = None

                cells[cell_i]["source"] = [line for line in cell["source"] if line is not None]

                # Remove cell if we've deleted all the lines
                if len(cells[cell_i]["source"]) == 0:
                    cells[cell_i] = None

                # Remove cell if remaining lines are only whitespace
                elif "" == re.sub("\s+", "", "".join(cells[cell_i]["source"])):
                    cells[cell_i] = None

            cells = [cell for cell in cells if cell is not None]


    table_of_contents = ["## Table of Contents\n", "<a id='top-of-page'></a>\n", "\n"]
    for i, name in enumerate(all_file_names):
        link = name.replace(" ", "-").replace("(", "").replace(")", "").replace(":", "").lower()
        table_of_contents += [f"- [{name}](#{link})\n"]
    
    cells.insert(0, new_markdown_cell(table_of_contents))

    if header is not None:
        cells.insert(0, new_markdown_cell(header))

    main_file_contents["cells"] = cells
    # printj(main_file_contents)

    if overwrite is True:
        write_json_file(filename + ".ipynb", main_file_contents)
    else:
        counter = 0
        while True:
            fname = filename + (f" {counter}" if counter > 0 else "") + ".ipynb"
            if os.path.exists(fname):
                counter += 1
                continue
            write_json_file(fname, main_file_contents)
            break



def write_json_file(fname, contents):
    with open(fname, "w+") as f:
        f.write(json.dumps(contents))


def read_file_as_json(name):
    with open(name,'r', encoding='utf-8') as f:
        file = f.read()
    return json.loads(file)


def printj(contents: dict):
    print(json.dumps(contents, indent=2))


def new_markdown_cell(source: list):
    return dict(
        cell_type = "markdown",
        metadata = {},
        source = source if source else [""],
    )



if __name__ == "__main__":

    combine(
        filename="8-combined (AUTO GENERATED)",
        line_filters = "%run 1-file.ipynb"
    )
